package com.miniai.model;

import com.codeai.tokenizer.CodeTokenizer;
import com.miniai.core.model.LanguageModel;
import com.miniai.core.tokenizer.Tokenizer;
import com.miniai.core.types.GenerateRequest;
import com.miniai.core.types.GenerateResponse;
import com.miniai.core.types.Usage;
import com.miniai.tokenizer.WhitespaceTokenizer;

import java.nio.file.Path;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

/**
 * Bigram ì–¸ì–´ ëª¨ë¸
 *
 * í•™ìŠµ í¬ì¸íŠ¸:
 * - ìƒì„± = "ë‹¤ìŒ í† í° ì˜ˆì¸¡" ë£¨í”„
 * - Bigram: prev í† í° ê¸°ë°˜ìœ¼ë¡œ next ì˜ˆì¸¡
 * - ìƒ˜í”Œë§: í™•ë¥  ë¶„í¬ì—ì„œ í† í° ì„ íƒ
 */
public class BigramModel implements LanguageModel {

    private final BigramArtifact artifact;
    private final Tokenizer tokenizer;
    private final String modelName;

    public BigramModel(BigramArtifact artifact, Tokenizer tokenizer) {
        this.artifact = artifact;
        this.tokenizer = tokenizer;
        this.modelName = "bigram-v1";
    }

    /**
     * Artifact íŒŒì¼ë¡œë¶€í„° ëª¨ë¸ ë¡œë“œ
     */
    public static BigramModel fromArtifact(Path artifactPath) {
        BigramArtifact artifact = BigramTrainer.loadArtifact(artifactPath);

        // Vocabularyì™€ í† í¬ë‚˜ì´ì € íƒ€ì…ìœ¼ë¡œ Tokenizer ìƒì„±
        Tokenizer tokenizer;
        String tokenizerType = artifact.getMetadata().getTokenizerType();

        if ("CodeTokenizer".equals(tokenizerType)) {
            tokenizer = new CodeTokenizer(artifact.getVocabulary());
            System.out.println("ğŸ”§ ëª¨ë¸ ë¡œë“œ: CodeTokenizer ì‚¬ìš©");
        } else {
            tokenizer = new WhitespaceTokenizer(artifact.getVocabulary());
            System.out.println("ğŸ“ ëª¨ë¸ ë¡œë“œ: WhitespaceTokenizer ì‚¬ìš©");
        }

        return new BigramModel(artifact, tokenizer);
    }

    @Override
    public GenerateResponse generate(GenerateRequest request) {
        long startTime = System.currentTimeMillis();

        // 1. Prompt í† í°í™”
        List<Integer> promptTokens = tokenizer.encode(request.getPrompt());
        if (promptTokens.isEmpty()) {
            throw new IllegalArgumentException("Promptê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤");
        }

        // 2. Sampler ìƒì„±
        Sampler sampler = new Sampler(
            request.getTemperature(),
            request.getTopK(),
            request.getSeed().orElse(null)
        );

        // 3. ìƒì„± ë£¨í”„
        List<Integer> generatedTokens = new ArrayList<>(promptTokens);
        int maxTokens = request.getMaxTokens();
        List<String> stopSequences = request.getStopSequences();

        for (int i = 0; i < maxTokens; i++) {
            // ë§ˆì§€ë§‰ í† í° ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ í† í° ì˜ˆì¸¡
            int prevToken = generatedTokens.get(generatedTokens.size() - 1);

            // ë‹¤ìŒ í† í° í›„ë³´ë“¤
            Map<Integer, Integer> nextCounts = artifact.getNextTokenCounts(prevToken);

            if (nextCounts.isEmpty()) {
                // ë” ì´ìƒ ìƒì„± ë¶ˆê°€ (dead end)
                break;
            }

            // ìƒ˜í”Œë§
            int nextToken = sampler.sample(nextCounts);
            generatedTokens.add(nextToken);

            // Stop sequence í™•ì¸
            if (shouldStop(generatedTokens, stopSequences)) {
                break;
            }
        }

        // 4. í† í° â†’ í…ìŠ¤íŠ¸
        String generatedText = tokenizer.decode(generatedTokens);

        // 5. Usage ê³„ì‚°
        Usage usage = new Usage(
            promptTokens.size(),
            generatedTokens.size() - promptTokens.size()
        );

        // 6. Latency ê³„ì‚°
        long latency = System.currentTimeMillis() - startTime;

        return new GenerateResponse(generatedText, usage, latency, modelName);
    }

    /**
     * Stop sequence í™•ì¸
     */
    private boolean shouldStop(List<Integer> tokens, List<String> stopSequences) {
        if (stopSequences.isEmpty()) {
            return false;
        }

        String currentText = tokenizer.decode(tokens);

        for (String stopSeq : stopSequences) {
            if (currentText.endsWith(stopSeq)) {
                return true;
            }
        }

        return false;
    }

    /**
     * ë‹¨ì¼ ë‹¤ìŒ í† í° ì˜ˆì¸¡
     */
    public int predictNext(int prevToken, double temperature, int topK, Long seed) {
        Map<Integer, Integer> nextCounts = artifact.getNextTokenCounts(prevToken);

        if (nextCounts.isEmpty()) {
            throw new IllegalStateException("í† í° " + prevToken + " ë‹¤ìŒì— ì˜¬ ìˆ˜ ìˆëŠ” í† í°ì´ ì—†ìŠµë‹ˆë‹¤");
        }

        Sampler sampler = new Sampler(temperature, topK, seed);
        return sampler.sample(nextCounts);
    }

    /**
     * íŠ¹ì • í† í° ë‹¤ìŒì— ì˜¬ ìˆ˜ ìˆëŠ” í† í°ë“¤ê³¼ í™•ë¥ 
     */
    public Map<Integer, Double> getNextTokenProbs(int prevToken) {
        Map<Integer, Integer> counts = artifact.getNextTokenCounts(prevToken);
        int total = counts.values().stream().mapToInt(Integer::intValue).sum();

        Map<Integer, Double> probs = new HashMap<>();
        for (Map.Entry<Integer, Integer> entry : counts.entrySet()) {
            probs.put(entry.getKey(), (double) entry.getValue() / total);
        }

        return probs;
    }

    @Override
    public String modelName() {
        return modelName;
    }

    public BigramArtifact getArtifact() {
        return artifact;
    }

    public Tokenizer getTokenizer() {
        return tokenizer;
    }

    @Override
    public String toString() {
        return String.format("BigramModel(vocab=%d, bigrams=%d)",
            artifact.getVocabulary().size(),
            artifact.getTotalBigramCount());
    }
}
